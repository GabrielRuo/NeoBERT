defaults:
  - tokenizer: google
  - model: 
    - neobert
    - 250M-opt
  - optimizer: adamw
  - scheduler: cosine_decay
  - dataset: contrastive
  - trainer: contrastive
  - dataloader: base
  - datacollator: base
  - _self_

seed: 0

hydra:
  run:
    dir: logs/hydra

wandb:
  name: null
  project: neo-bert
  entity: sarath-chandar
  tags: ["finetuning"]
  dir: logs/wandb
  mode: online
  log_interval: 100
  
scheduler:
  warmup_steps: 2000
  decay_steps: 50000

dataloader:
  target_bsz: 128